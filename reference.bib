@article{feynman1965feynman,
  title={The feynman lectures on physics; vol. i},
  author={Feynman, Richard P and Leighton, Robert B and Sands, Matthew and Hafner, Everett M},
  journal={American Journal of Physics},
  volume={33},
  number={9},
  pages={750--752},
  year={1965},
  publisher={American Association of Physics Teachers}
}

@misc{bengio_international_2025,
	title = {International {AI} {Safety} {Report}},
	copyright = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2501.17805},
	doi = {10.48550/ARXIV.2501.17805},
	abstract = {The first International AI Safety Report comprehensively synthesizes the current evidence on the capabilities, risks, and safety of advanced AI systems. The report was mandated by the nations attending the AI Safety Summit in Bletchley, UK. Thirty nations, the UN, the OECD, and the EU each nominated a representative to the report's Expert Advisory Panel. A total of 100 AI experts contributed, representing diverse perspectives and disciplines. Led by the report's Chair, these independent experts collectively had full discretion over the report's content.},
	urldate = {2025-11-25},
	publisher = {arXiv},
	author = {Bengio, Yoshua and Mindermann, Sören and Privitera, Daniel and Besiroglu, Tamay and Bommasani, Rishi and Casper, Stephen and Choi, Yejin and Fox, Philip and Garfinkel, Ben and Goldfarb, Danielle and Heidari, Hoda and Ho, Anson and Kapoor, Sayash and Khalatbari, Leila and Longpre, Shayne and Manning, Sam and Mavroudis, Vasilios and Mazeika, Mantas and Michael, Julian and Newman, Jessica and Ng, Kwan Yee and Okolo, Chinasa T. and Raji, Deborah and Sastry, Girish and Seger, Elizabeth and Skeadas, Theodora and South, Tobin and Strubell, Emma and Tramèr, Florian and Velasco, Lucia and Wheeler, Nicole and Acemoglu, Daron and Adekanmbi, Olubayo and Dalrymple, David and Dietterich, Thomas G. and Felten, Edward W. and Fung, Pascale and Gourinchas, Pierre-Olivier and Heintz, Fredrik and Hinton, Geoffrey and Jennings, Nick and Krause, Andreas and Leavy, Susan and Liang, Percy and Ludermir, Teresa and Marda, Vidushi and Margetts, Helen and McDermid, John and Munga, Jane and Narayanan, Arvind and Nelson, Alondra and Neppel, Clara and Oh, Alice and Ramchurn, Gopal and Russell, Stuart and Schaake, Marietje and Schölkopf, Bernhard and Song, Dawn and Soto, Alvaro and Tiedrich, Lee and Varoquaux, Gaël and Yao, Andrew and Zhang, Ya-Qin and Albalawi, Fahad and Alserkal, Marwan and Ajala, Olubunmi and Avrin, Guillaume and Busch, Christian and de Carvalho, André Carlos Ponce de Leon Ferreira and Fox, Bronwyn and Gill, Amandeep Singh and Hatip, Ahmet Halit and Heikkilä, Juha and Jolly, Gill and Katzir, Ziv and Kitano, Hiroaki and Krüger, Antonio and Johnson, Chris and Khan, Saif M. and Lee, Kyoung Mu and Ligot, Dominic Vincent and Molchanovskyi, Oleksii and Monti, Andrea and Mwamanzi, Nusu and Nemer, Mona and Oliver, Nuria and Portillo, José Ramón López and Ravindran, Balaraman and Rivera, Raquel Pezoa and Riza, Hammam and Rugege, Crystal and Seoighe, Ciarán and Sheehan, Jerry and Sheikh, Haroon and Wong, Denise and Zeng, Yi},
	year = {2025},
	note = {Version Number: 1},
	keywords = {Artificial Intelligence (cs.AI), Computers and Society (cs.CY), FOS: Computer and information sciences, Machine Learning (cs.LG)},
}

@misc{the_turing_way_community_2024_13882307,
  author       = {The Turing Way Community and
                  Scriberia},
  title        = {Illustrations from The Turing Way: Shared under
                   CC-BY 4.0 for reuse
                  },
  month        = oct,
  year         = 2024,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.13882307},
  url          = {https://doi.org/10.5281/zenodo.13882307},
}


@misc{lin_ai_2025,
	title = {{AI} {Safety} vs. {AI} {Security}: {Demystifying} the {Distinction} and {Boundaries}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	shorttitle = {{AI} {Safety} vs. {AI} {Security}},
	url = {https://arxiv.org/abs/2506.18932},
	doi = {10.48550/ARXIV.2506.18932},
	abstract = {Artificial Intelligence (AI) is rapidly being integrated into critical systems across various domains, from healthcare to autonomous vehicles. While its integration brings immense benefits, it also introduces significant risks, including those arising from AI misuse. Within the discourse on managing these risks, the terms "AI Safety" and "AI Security" are often used, sometimes interchangeably, resulting in conceptual confusion. This paper aims to demystify the distinction and delineate the precise research boundaries between AI Safety and AI Security. We provide rigorous definitions, outline their respective research focuses, and explore their interdependency, including how security breaches can precipitate safety failures and vice versa. Using clear analogies from message transmission and building construction, we illustrate these distinctions. Clarifying these boundaries is crucial for guiding precise research directions, fostering effective cross-disciplinary collaboration, enhancing policy effectiveness, and ultimately, promoting the deployment of trustworthy AI systems.},
	urldate = {2025-11-24},
	publisher = {arXiv},
	author = {Lin, Zhiqiang and Sun, Huan and Shroff, Ness},
	year = {2025},
	note = {Version Number: 1},
	keywords = {Artificial Intelligence (cs.AI), Computers and Society (cs.CY), FOS: Computer and information sciences, Cryptography and Security (cs.CR)},
}


@article{kolstoe_trinity_2024,
	title = {The trinity of good research: {Distinguishing} between research integrity, ethics, and governance},
	volume = {31},
	issn = {0898-9621, 1545-5815},
	shorttitle = {The trinity of good research},
	url = {https://www.tandfonline.com/doi/full/10.1080/08989621.2023.2239712},
	doi = {10.1080/08989621.2023.2239712},
	language = {en},
	number = {8},
	urldate = {2025-11-24},
	journal = {Accountability in Research},
	author = {Kolstoe, Simon E. and Pugh, Jonathan},
	month = dec,
	year = {2024},
	pages = {1222--1241},
	file = {Volltext:/Users/rshigapo/Zotero/storage/7DKEND6Y/Kolstoe und Pugh - 2024 - The trinity of good research Distinguishing between research integrity, ethics, and governance.pdf:application/pdf},
}

@online{unesco_ai_ethics_2022,
  author       = {{United Nations Educational, Scientific and Cultural Organization (UNESCO)}},
  title        = {Recommendation on the Ethics of Artificial Intelligence},
  year         = {2022},
  url          = {https://www.unesco.org/en/artificial-intelligence/recommendation-ethics},
  organization = {UNESCO},
  note         = {Accessed: 2025-12-16}
}

@misc{allea_all_european_academies_2023,
  author       = {ALLEA},
  title        = {The European Code of Conduct for Research
                   Integrity – Revised Edition 2023
                  },
  month        = jun,
  year         = 2023,
  publisher    = {ALLEA},
  doi          = {10.26356/ECOC},
  url          = {https://doi.org/10.26356/ECOC},
}

@techreport{enrico_glerean_fundamentals,
	type = {Training curriculum on {AI} and data protection},
	title = {Fundamentals of {Secure} {AI} {Systems} with {Personal} {Data}},
	url = {https://www.edpb.europa.eu/system/files/2025-06/spe-training-on-ai-and-data-protection-technical_en.pdf},
	year = {2025},
	author = {{Enrico Glerean}},
}