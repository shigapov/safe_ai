# Research Integrity

## Research integrity: Who defines that?

* International, national, funders, and university Codes of Conduct for Research Integrity (e.g., ALLEA European Code of Conduct, Singapore Statement on Research Integrity, DFG’s "Guidelines for Safeguarding Good Research Practice”)
* Research communities define domain-specific integrity standards
* Local integrity offices, local ombudspersons, and Ombuds Committee for Research Integrity in Germany are points of contact for researchers to report and seek advice on issues related to research integrity
* Publishers and journals create policies related to research integrity (data policy, AI policy, general guidelines for authors, etc.)
* Committee on Publication Ethics issues guidelines for authors and reviewers

## Main research integrity documents for using AI in research

General documents which do not specifically mention „AI“:
* ALLEA European Code of Conduct for Research Integrity (https://allea.org/code-of-conduct)
* Singapore Statement on Research Integrity (https://www.wcrif.org/statement)
* DFG. (2025). Guidelines for Safeguarding Good Research Practice. Code of Conduct. https://doi.org/10.5281/zenodo.14281892
AI-specific documents:
* Living guidelines on the responsible use of generative AI in research for researchers, research organizations, and research funding organizations (https://research-and-innovation.ec.europa.eu/document/download/2b6cf7e5-36ac-41cb-aab5-0d32050143dc_en)
* AI policies and recommendations of research organizations (e.g., Helmholtz: https://www.helmholtz.de/assets/helmholtz_gemeinschaft/Downloads/Helmholtz_Recommendations_on_use_of_AI_Version_1.0.pdf)
* AI policies of funders, journals, and publishers

## Research misconduct in European Code of Conduct

According to {cite:p}`allea_all_european_academies_2023`:

Research misconduct is traditionally defined as fabrication, falsification, or plagiarism in proposing, performing, or reviewing research, or in reporting research results:
* Fabrication is making up data or results and recording them as if they were real.
* Falsification is manipulating research materials, equipment, images, or processes, or changing, omitting, or suppressing data or results without justification.
* Plagiarism is using other people’s work or ideas without giving proper credit to the original source.

## DFG and research misconduct: Scope and Definitions

The following scope and definitions can be found in DFG, “Rules of Procedure for Dealing with Scientific Misconduct”, https://www.dfg.de/resource/blob/339200/dfg-80-01-v0524-en.pdf

"§1 (2): These Rules of Procedure apply if the respondent is one of the following with regard to the allegation:
1. A grant applicant to the DFG
2. A grant recipient funded by the DFG,
3. Individuals with a high level of scientific responsibility in connection with funding proposals submitted by higher education institutions or non-university research institutions,
4. individuals reviewing a proposal for the DFG or
5. A member of a DFG committee or a committee supported by the DFG in administering funding instruments who participates in advisory, review, evaluation or decision-making procedures."

"§2: Scientific Misconduct 
(1) $^1$An individual pursuant to § 1 (2) nos. 1-3 commits scientific misconduct if they do any of the following in particular, either intentionally or with gross negligence:
1. make misrepresentations (§ 3),
2. appropriate others’ research achievements without justification (§ 4),
3. interfere with others’ research (§ 5),
4. participate in the scientific misconduct of others by way of co-authorship (§ 6) or
5. neglect their supervisory duties (§ 7).
$^2$Anyone who intentionally participates in the misconduct of others is also guilty of scientific misconduct (§ 8).
(2) A person pursuant to § 1 (2) nos. 4 and 5 commits scientific misconduct if they do any of the following, either intentionally or with gross negligence:
1. breach confidentiality (§ 9),
2. fail to disclose circumstances that give rise to the appearance of conflict of interest (§ 10) or
3. inadmissibly give unfair preferential treatment to others (§ 11).
"

## Spectrum of questionable research practices

Although usually questionable research practices are defined as something less dangerous as scientific misconduct, https://doi.org/10.37672/UKRIO.2023.02.QRPs proposed to define a spectrum of questionable practices:

* QRP is “a spectrum of behaviours, ranging from honest errors and mistakes at one end, through to more serious behaviours at the other”.
* “Everyone involved in research may at times engage in QRPs, and thus it is up to everyone involved in research to recognise and address the problem in their own, as well as others’ research”.

QRPs with AI don’t just repeat traditional integrity risks — they amplify them. https://doi.org/10.5281/zenodo.17349510

A lack of AI literacy may unintentionally lead to the whole spectrum of questionable research practices. Not necessarily your own AI literacy, but that of a co-author, project partner, or student assistant.

## Tool: Retraction Watch Database, Blog, etc.

```{exercise} Retraction Watch Database and Blog

* Find the posts at https://retractionwatch.com related to retractions of papers due to use of AI
* Download the retraction watch database https://gitlab.com/crossref/retraction-watch-data and find retracted papers with "AI" in the titles
* Read the list of papers with evidence of ChatGPT-writing https://retractionwatch.com/papers-and-peer-reviews-with-evidence-of-chatgpt-writing. Analyze and discuss the reasons for retraction.
```

## Tool: Academ-AI

```{exercise} Academ-AI

* Read the samples of papers with suspected undeclared AI usage in the academic literature at https://www.academ-ai.info. Discuss strong and weak markers of using AI in research.
* Read preprint https://doi.org/10.48550/arXiv.2411.15218  and discuss it with colleagues
```

## Tool: Research Integrity Risk Index

```{exercise} Research Integrity Risk Index

* Read preprint https://doi.org/10.1007/s11192-025-05480-2  and discuss it with colleagues
* Analyze https://sites.aub.edu.lb/lmeho/ri2. How can it help you to select potential project partners?
```

## Living guidelines on the responsible use of generative AI in research for researchers

1. Remain ultimately responsible for scientific output.
2. Use generative AI transparently.
3. Pay particular attention to issues related to privacy, confidentiality and intellectual property rights when sharing sensitive or protected information with AI tools.
4. Respect applicable national, EU and international legislation.
5. Continuously learn how to use generative AI tools properly to maximise their benefits, including by undertaking training.
6. Refrain from using generative AI tools substantially in sensitive activities that could impact other researchers or organisations (for example peer review, evaluation of research proposals, etc).

Source: https://research-and-innovation.ec.europa.eu/document/download/2b6cf7e5-36ac-41cb-aab5-0d32050143dc_en

## Living guidelines on the responsible use of generative AI in research for research organizations

The guidelines for research organizations include:
“3. Reference or integrate these generative AI guidelines into their general research guidelines for good research practices and ethics.
Using these guidelines as a basis for discussion, research organisations openly consult their research staff and stakeholders on the use of generative AI and related policies.
Research organisations apply these guidelines whenever possible. If needed, they could be complemented with specific additional recommendations and/or exceptions that should be published for transparency.”

## German FAQ on AI and research integrity

* DE: Frisch, K. (2025). FAQ Künstliche Intelligenz und gute wissenschaftliche Praxis - Version 2. Zenodo. https://doi.org/10.5281/zenodo.17349995 
* EN: Frisch, Katrin (2025). FAQ Artificial Intelligence and Research Integrity. Version 2. Zenodo. https://doi.org/10.5281/zenodo.17349995 
* More resources by Dr. Katrin Frisch on research data and AI in context of research integrity are available at https://ombudsgremium.de/9806/research-data-and-ai/?lang=en 

## Tool: Artificial Intelligence Disclosure (AID)

```{exercise} Artificial Intelligence Disclosure (AID)

* Test https://aidframework.org
```

## Tool: AI Attribution Toolkit

```{exercise} AI Attribution Toolkit

* Test https://aiattribution.github.io/interpret-attribution
```

## Tool: GAIDeT Declaration Generator 

```{exercise} GAIDeT Declaration Generator 

* Test https://panbibliotekar.github.io/gaidet-declaration/index.htm
* Read paper https://doi.org/10.1080/08989621.2025.2544331 and discuss it with colleagues
```

## Tool: Decision tree for responsible application of AI

```{exercise} Decision tree for responsible application of AI

* Apply the decision tree for responsible application of AI to your AI use case: American Association for the Advancement of Science (AAAS). Decision Tree for the Responsible Application of Artificial Intelligence (v1.0): [Online]. (2023). https://www.aaas.org/sites/default/files/2023-08/AAAS%20Decision%20Tree.pdf 
```

```{exercise} Quiz

Who do you believe is responsible for research integrity when AI systems are used?
* Users of AI systems
* Supervisors, PIs, and project managers
* Co-authors
* Project partners
* Institutions and support teams
* Developers and providers of AI systems
* All of the above
```