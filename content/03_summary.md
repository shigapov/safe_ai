# Summary

From Introduction:

Before you use any AI system, ask yourself the following questions:
* Is the hardware safe and secure?
* Is the software safe and secure?
* Is the data (including training, validation, testing, augmented, input, and output) safe and secure?
* Is the model safe and secure?
* Are the networks safe and secure?

From the Part 1:

* Freedom of research under ethical, integrity, and governance (legal and regulatory) constraints
   * Research Ethics (ethical assessment by ethical committees and funders)
   * Research Integrity (scientific misconduct and questionable research practices)
   * Research Governance (GDPR, Copyright, EU AI Act, and export control regulations)
* AI risks, AI safety, and AI security
   * AI safety risks from the first international AI safety report
   * AI security risks from the OWASP AI-Exchange
* Risk management
  * Review of approaches
  * Risk management framework
  * Defense in Depth

From the Part 2:

* Risk management in research projects
   * Risk management framework adapted to the trinity of risks (ethical, integrity, and governance)
   * Defense in Depth in three dimensions: people, technology, and processes
* Hands-On: Risk management across the research lifecycle
   * Plan & design, collect & create, analyze & collaborate, evaluate & archive, share & disseminate, access & reuse
   * AI-researchers (the whole research lifecycle in one AI system)
* AI policies and checklists for research groups and research projects